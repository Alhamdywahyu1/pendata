{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Pemodelan Clustering â€” Deep Dive K-Means\n",
    "\n",
    "### Jembatan Konseptual: Dari Klasifikasi ke Clustering\n",
    "\n",
    "Selamat datang di bagian **2.a** dari seri pemodelan kita. Kita telah menyelesaikan seri pemodelan **Klasifikasi (Supervised Learning)**, di mana tujuan utamanya adalah melatih model untuk memprediksi sebuah label yang sudah ada sebelumnya (misalnya, `species`).\n",
    "\n",
    "Sekarang, kita memasuki dunia **Clustering (Unsupervised Learning)**. Di sini, paradigmanya berubah total. Kita tidak lagi memiliki \"jawaban\" atau label yang benar. Tugas kita adalah menjadi seorang detektif data, mencoba menemukan struktur atau kelompok-kelompok alami (`cluster`) di dalam data berdasarkan kemiripan fitur-fiturnya saja.\n",
    "\n",
    "### Filosofi K-Means: \"Menemukan Pusat Gravitasi Kelompok\"\n",
    "\n",
    "Bayangkan Anda diminta untuk mengatur setumpuk belanjaan yang berbeda jenis ke dalam `K` keranjang. Algoritma K-Means bekerja dengan cara yang sangat mirip:\n",
    "1.  **Inisialisasi:** Menempatkan `K` titik pusat (disebut **centroid**) secara acak di dalam data.\n",
    "2.  **Assignment Step:** Menetapkan setiap titik data ke centroid terdekat, membentuk `K` cluster.\n",
    "3.  **Update Step:** Memperbarui posisi setiap centroid dengan memindahkannya ke pusat gravitasi (rata-rata) dari semua titik data yang menjadi anggotanya.\n",
    "4.  **Iterasi:** Mengulangi langkah 2 dan 3 sampai posisi centroid tidak lagi berubah secara signifikan.\n",
    "\n",
    "Tujuan K-Means adalah meminimalkan **inertia**, yaitu total kuadrat jarak antara setiap titik data dengan centroid clusternya.\n",
    "\n",
    "Di notebook ini, kita akan menerapkan K-Means pada dataset Iris, menentukan jumlah cluster `K` yang optimal, dan mengevaluasi seberapa baik hasil clustering tersebut cocok dengan label spesies yang sebenarnya (yang akan kita sembunyikan selama pelatihan)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 1: Setup Mandiri & Persiapan Data\n",
    "\n",
    "Sebagai notebook mandiri, sel pertama ini akan menangani semua yang kita butuhkan: mengimpor pustaka, memuat data mentah, dan melakukan pra-pemrosesan yang diperlukan untuk K-Means (yaitu, penskalaan fitur)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# SETUP MANDIRI UNTUK PEMODELAN K-MEANS\n",
    "# =======================================================\n",
    "\n",
    "# 1. Import Pustaka\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "print(\"Pustaka yang dibutuhkan telah diimpor.\")\n",
    "\n",
    "# 2. Memuat dan Membuat DataFrame Awal\n",
    "iris = load_iris()\n",
    "df_iris = pd.DataFrame(data=iris.data, columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n",
    "# Kita simpan label asli untuk evaluasi nanti, tapi tidak akan digunakan saat melatih model\n",
    "df_iris['true_species'] = [iris.target_names[i] for i in iris.target]\n",
    "true_labels = iris.target # Simpan label numerik asli\n",
    "print(\"Dataset Iris mentah berhasil dibuat.\")\n",
    "\n",
    "# 3. Pra-Pemrosesan: Penskalaan Fitur\n",
    "# K-Means sangat sensitif terhadap skala data karena berbasis jarak. Penskalaan adalah wajib.\n",
    "print(\"\\nMemulai pra-pemrosesan (penskalaan)... \")\n",
    "features = df_iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "print(\"Penskalaan fitur selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 2: Menentukan Jumlah Cluster Optimal (`K`) dengan Metode Siku (Elbow Method)\n",
    "\n",
    "Tantangan terbesar dalam K-Means adalah menentukan berapa banyak cluster (`K`) yang harus kita cari. Metode Siku adalah teknik populer untuk membantu kita membuat keputusan ini secara visual.\n",
    "\n",
    "Kita akan menjalankan K-Means dengan jumlah `K` yang berbeda-beda (misalnya, dari 1 sampai 10) dan menghitung nilai **inertia** untuk masing-masing. Kita mencari titik \"siku\" pada grafik, yaitu titik di mana penambahan cluster baru tidak lagi memberikan penurunan inertia yang signifikan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List untuk menyimpan nilai inertia\n",
    "inertia_list = []\n",
    "k_range = range(1, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++', n_init=10, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia_list.append(kmeans.inertia_)\n",
    "\n",
    "# Membuat plot Elbow Method\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.plot(k_range, inertia_list, color='blue', linestyle='--', marker='o', markersize=8, markerfacecolor='red')\n",
    "plt.title('Elbow Method untuk Menentukan K Optimal', fontsize=16)\n",
    "plt.xlabel('Jumlah Cluster (K)')\n",
    "plt.ylabel('Inertia (Within-Cluster Sum of Squares)')\n",
    "plt.xticks(k_range)\n",
    "plt.annotate('Titik Siku (Elbow Point)', xy=(3, inertia_list[2]), xytext=(4, 150), \n",
    "             arrowprops=dict(facecolor='black', shrink=0.05), fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis Grafik Siku:**\n",
    "Grafik di atas menunjukkan \"siku\" yang sangat jelas pada **K=3**. Dari K=1 ke K=2, dan K=2 ke K=3, nilai inertia turun secara drastis. Namun, setelah K=3, penurunan inertia menjadi sangat landai. Ini adalah indikasi kuat bahwa jumlah cluster alami yang paling sesuai untuk data ini adalah 3, yang secara kebetulan sama dengan jumlah spesies asli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 3: Membangun & Visualisasi Model K-Means Optimal\n",
    "\n",
    "Setelah menentukan `K=3` sebagai jumlah cluster yang optimal, sekarang kita akan melatih model K-Means final dan memvisualisasikan hasilnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi dan latih model K-Means optimal\n",
    "kmeans_optimal = KMeans(n_clusters=3, init='k-means++', n_init=10, random_state=42)\n",
    "predicted_labels = kmeans_optimal.fit_predict(X_scaled)\n",
    "\n",
    "# Tambahkan label cluster hasil prediksi ke DataFrame asli\n",
    "df_iris['predicted_cluster'] = predicted_labels\n",
    "\n",
    "# Dapatkan posisi centroid\n",
    "centroids = kmeans_optimal.cluster_centers_\n",
    "\n",
    "# Visualisasi hasil clustering pada dua fitur paling penting (petal length vs petal width)\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.scatterplot(data=df_iris, x='petal_length', y='petal_width', hue='predicted_cluster', \n",
    "                palette='viridis', s=100, alpha=0.8, legend='full')\n",
    "\n",
    "# Plot centroid (perlu di-unscale untuk plot pada sumbu asli)\n",
    "# Kita akan plot pada data yang diskalakan untuk kesederhanaan visualisasi hubungan\n",
    "df_scaled_pd = pd.DataFrame(X_scaled, columns=features.columns)\n",
    "df_scaled_pd['predicted_cluster'] = predicted_labels\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.scatterplot(data=df_scaled_pd, x='petal_length', y='petal_width', hue='predicted_cluster', \n",
    "                palette='viridis', s=100, alpha=0.8, legend='full')\n",
    "plt.scatter(centroids[:, 2], centroids[:, 3], s=300, c='red', marker='X', label='Centroids')\n",
    "plt.title('Hasil Clustering K-Means (K=3) pada Data yang Diskalakan', fontsize=16)\n",
    "plt.xlabel('Petal Length (Scaled)')\n",
    "plt.ylabel('Petal Width (Scaled)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisasi ini menunjukkan tiga kelompok data yang terpisah dengan baik, dengan setiap centroid (tanda X merah) berada di tengah-tengah clusternya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 4: Evaluasi Kualitas Cluster\n",
    "\n",
    "Dalam kasus khusus ini, kita memiliki \"kemewahan\" untuk membandingkan hasil clustering kita dengan label spesies yang sebenarnya. Ini memungkinkan kita untuk mengevaluasi seberapa baik K-Means berhasil menemukan struktur alami data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Perbandingan Kualitatif dengan Tabel Silang (Crosstab)\n",
    "contingency_table = pd.crosstab(df_iris['true_species'], df_iris['predicted_cluster'])\n",
    "print(\"--- Tabel Silang: Label Asli vs. Hasil Cluster ---\")\n",
    "display(contingency_table)\n",
    "\n",
    "# 2. Perbandingan Visual\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8), sharey=True)\n",
    "sns.scatterplot(data=df_iris, x='petal_length', y='petal_width', hue='true_species', \n",
    "                palette='plasma', s=100, alpha=0.8, ax=axes[0])\n",
    "axes[0].set_title('Distribusi Data Berdasarkan Label Asli (Species)', fontsize=14)\n",
    "\n",
    "sns.scatterplot(data=df_iris, x='petal_length', y='petal_width', hue='predicted_cluster', \n",
    "                palette='viridis', s=100, alpha=0.8, ax=axes[1])\n",
    "axes[1].set_title('Distribusi Data Berdasarkan Hasil Clustering K-Means', fontsize=14)\n",
    "plt.suptitle('Perbandingan Visual Label Asli vs. Hasil Clustering', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "# 3. Evaluasi Kuantitatif\n",
    "silhouette = silhouette_score(X_scaled, predicted_labels)\n",
    "ars = adjusted_rand_score(true_labels, predicted_labels)\n",
    "\n",
    "print(\"\\n--- Metrik Evaluasi Kuantitatif ---\")\n",
    "print(f\"Silhouette Score: {silhouette:.4f}\")\n",
    "print(f\"Adjusted Rand Score (ARS): {ars:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisis Evaluasi:**\n",
    "* **Tabel Silang & Visual:** Hasilnya luar biasa. Cluster 1 secara sempurna memetakan ke spesies `setosa`. Cluster 0 dan 2 sebagian besar memetakan ke `versicolor` dan `virginica`, dengan sedikit tumpang tindihâ€”sama persis seperti yang kita lihat pada struktur data aslinya.\n",
    "* **Silhouette Score (0.4599):** Skor ini (berkisar dari -1 hingga 1) menunjukkan bahwa cluster yang terbentuk cukup padat dan terpisah dengan baik. Skor positif menandakan kualitas clustering yang baik.\n",
    "* **Adjusted Rand Score (0.8198):** Skor ini (berkisar dari -1 hingga 1, di mana 1 adalah sempurna) sangat tinggi. Ini secara kuantitatif membuktikan bahwa pengelompokan yang ditemukan oleh K-Means sangat mirip dengan pengelompokan spesies yang sebenarnya.\n",
    "\n",
    "Kesimpulannya, K-Means berhasil dengan sangat baik dalam menemukan struktur tersembunyi di dalam dataset Iris tanpa pernah melihat labelnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penutup dan Jembatan Konseptual\n",
    "\n",
    "Dalam notebook ini, kita telah melakukan perjalanan lengkap dengan K-Means: mulai dari memahami konsepnya, menentukan parameter `K` yang paling penting menggunakan Elbow Method, melatih model, hingga mengevaluasi hasilnya dengan berbagai cara.\n",
    "\n",
    "Salah satu ciri khas K-Means adalah ia melakukan **hard clustering**, yang berarti setiap titik data secara tegas menjadi anggota dari **satu** cluster saja.\n",
    "\n",
    "#### Jembatan ke Seri Selanjutnya\n",
    "\n",
    "Bagaimana jika sebuah titik data memiliki kemiripan dengan lebih dari satu kelompok? Di sinilah konsep *soft clustering* masuk.\n",
    "\n",
    "Pada **bagian selanjutnya (2.b)**, kita akan menjelajahi **Fuzzy C-Means**, sebuah metode clustering yang lebih fleksibel di mana setiap titik data bisa menjadi anggota dari beberapa cluster sekaligus dengan tingkat keanggotaan yang berbeda."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}